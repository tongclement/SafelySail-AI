{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n-seg.pt\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/clementtongpersonal/Desktop/Programming/2022/SafelySail-AI/dataset/img_29er Sailing medemblik #2 /frame399.jpg: 384x640 2 persons, 2 boats, 75.7ms\n",
      "Speed: 0.5ms pre-process, 75.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([4, 6])\n",
      "dtype: torch.float32\n",
      " + tensor([[1.06700e+03, 3.35000e+02, 1.43300e+03, 8.15000e+02, 8.38304e-01, 0.00000e+00],\n",
      "        [1.38500e+03, 4.28000e+02, 1.61300e+03, 7.75000e+02, 3.09309e-01, 0.00000e+00],\n",
      "        [1.67000e+02, 6.00000e+01, 1.63800e+03, 1.07400e+03, 2.66216e-01, 8.00000e+00],\n",
      "        [1.69000e+02, 4.71000e+02, 1.62900e+03, 1.07500e+03, 2.57990e-01, 8.00000e+00]])Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Masks'> masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([4, 384, 640])\n",
      "dtype: torch.float32\n",
      " + tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])]\n",
      "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([4, 6])\n",
      "dtype: torch.float32\n",
      " + tensor([[1.06700e+03, 3.35000e+02, 1.43300e+03, 8.15000e+02, 8.38304e-01, 0.00000e+00],\n",
      "        [1.38500e+03, 4.28000e+02, 1.61300e+03, 7.75000e+02, 3.09309e-01, 0.00000e+00],\n",
      "        [1.67000e+02, 6.00000e+01, 1.63800e+03, 1.07400e+03, 2.66216e-01, 8.00000e+00],\n",
      "        [1.69000e+02, 4.71000e+02, 1.62900e+03, 1.07500e+03, 2.57990e-01, 8.00000e+00]])Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Masks'> masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([4, 384, 640])\n",
      "dtype: torch.float32\n",
      " + tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])]\n"
     ]
    }
   ],
   "source": [
    "# accepts all formats - image/dir/Path/URL/video/PIL/ndarray. 0 for webcam\n",
    "#results = model.predict(source=\"2\")\n",
    "#for result in results:\n",
    "#    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "#    masks = result.masks  # Masks object for segmenation masks outputs\n",
    "#    probs = result.probs\n",
    "#    print(f\"boxes {boxes}, masks {masks}, probs {probs}\")\n",
    "\n",
    "#webcam test\n",
    "#results = model(source=\"2\", stream=True, show=True, half=True, task=\"segment\", save_conf=True)\n",
    "\n",
    "#using images from the dataset\n",
    "results = model(source=\"dataset/img_29er Sailing medemblik #2 /frame399.jpg\", stream=False, show=True, half=True, task=\"segment\", save_conf=True)\n",
    "\n",
    "# generator of Results objects\n",
    "\n",
    "print(results.__str__())\n",
    "print(results)\n",
    "for r in results:\n",
    "    boxes = r.boxes  # Boxes object for bbox outputs\n",
    "    masks = r.masks  # Masks object for segmenation masks outputs\n",
    "    probs = r.probs  # Class probabilities for classification outputs\n",
    "    #annotations = r.\n",
    "    #print(f\" r itself {r}, boxes {boxes}, masks {masks}, probs {probs}\")\n",
    "#results = model.predict(source=\"folder\", show=True) # Display preds. Accepts all YOLO predict arguments\n",
    "\n",
    "# from PIL\n",
    "#im1 = Image.open(\"bus.jpg\")\n",
    "#results = model.predict(source=im1, save=True)  # save plotted images\n",
    "\n",
    "# from ndarray\n",
    "#im2 = cv2.imread(\"bus.jpg\")\n",
    "#results = model.predict(source=im2, save=True, save_txt=True)  # save predictions as labels\n",
    "\n",
    "# from list of PIL/ndarray\n",
    "#results = model.predict(source=[im1, im2])c"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
